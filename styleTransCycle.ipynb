{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2image(tensor):\n",
    "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1:\n",
    "        image = np.tile(image, (3,1,1))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "#what even: track training\n",
    "class Logger():\n",
    "    def __init__(self, n_epochs, batches_epoch):\n",
    "        #self.viz = Visdom()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batches_epoch = batches_epoch\n",
    "        self.epoch = 1\n",
    "        self.batch = 1\n",
    "        self.prev_time = time.time()\n",
    "        self.mean_period = 0\n",
    "        self.losses = {}\n",
    "        self.loss_windows = {}\n",
    "        self.image_windows = {}\n",
    "\n",
    "\n",
    "    def log(self, losses=None, images=None):\n",
    "        self.mean_period += (time.time() - self.prev_time)\n",
    "        self.prev_time = time.time()\n",
    "\n",
    "        sys.stdout.write('\\rEpoch %03d/%03d [%04d/%04d] -- ' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\n",
    "\n",
    "        for i, loss_name in enumerate(losses.keys()):\n",
    "            if loss_name not in self.losses:\n",
    "                self.losses[loss_name] = losses[loss_name].item()   #data[0]\n",
    "            else:\n",
    "                self.losses[loss_name] += losses[loss_name].item()    #data[0]\n",
    "\n",
    "            if (i+1) == len(losses.keys()):\n",
    "                sys.stdout.write('%s: %.4f -- ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "            else:\n",
    "                sys.stdout.write('%s: %.4f | ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "\n",
    "        batches_done = self.batches_epoch*(self.epoch - 1) + self.batch\n",
    "        batches_left = self.batches_epoch*(self.n_epochs - self.epoch) + self.batches_epoch - self.batch \n",
    "        sys.stdout.write('ETA: %s' % (datetime.timedelta(seconds=batches_left*self.mean_period/batches_done)))\n",
    "        \n",
    "        # End of epoch\n",
    "        if (self.batch % self.batches_epoch) == 0:\n",
    "            \n",
    "            # Plot losses\n",
    "            for loss_name, loss in self.losses.items():\n",
    "                #if loss_name not in self.loss_windows:\n",
    "                 #   self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), \n",
    "                 #                                                   opts={'xlabel': 'epochs', 'ylabel': loss_name, 'title': loss_name})\n",
    "                #else:\n",
    "                    #self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), win=self.loss_windows[loss_name], update='append')\n",
    "                # Reset losses for next epoch\n",
    "                self.losses[loss_name] = 0.0 # ?\n",
    "            \n",
    "            \n",
    "            self.epoch += 1\n",
    "            self.batch = 1\n",
    "            sys.stdout.write('\\n')\n",
    "        else:\n",
    "            self.batch += 1\n",
    "\n",
    "        \n",
    "#discriminator is trained on buffer images rather than immediate output of generator\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"black hole\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "\n",
    "#lr update\n",
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"decay should start earlier\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*')) #datasets titled A and B\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
    "\n",
    "        if self.unaligned:\n",
    "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]).convert('RGB'))\n",
    "        else:\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]).convert('RGB'))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "├── datasets                   \n",
    "|   ├── <dataset_name>         #vangogh2photo\n",
    "|   |   ├── train              #training\n",
    "|   |   |   ├── A              #domain A images (gogh)\n",
    "|   |   |   └── B              #domain B images (photos)\n",
    "|   |   └── test               #testing\n",
    "|   |   |   ├── A              #domain A images (gogh)\n",
    "|   |   |   └── B              #domain B images (photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def myimshow(image, ax=plt):\n",
    "    image = image.to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image < 0] = 0\n",
    "    image[image > 1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample images\n",
    "\n",
    "size = 256 #crop size\n",
    "dataroot = './vangogh2photo/'\n",
    "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \n",
    "                transforms.CenterCrop(size), \n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "\n",
    "\n",
    "train_test = ImageDataset(dataroot, transforms_=transforms_, unaligned=True)\n",
    "x = train_test.__getitem__(index =50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimshow(x[\"A\"]) #gogh\n",
    "#myimshow(x[\"B\"]) #photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#used within the generator\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        #initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        #downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        #residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        #upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        #output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        #series of conv layers\n",
    "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(128), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(256), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
    "                    nn.InstanceNorm2d(512), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        #classification layer\n",
    "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        #average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize training\n",
    "\n",
    "epoch = 0\n",
    "n_epochs = 5\n",
    "batchSize = 1\n",
    "dataroot = './vangogh2photo/'\n",
    "lr = 0.001 \n",
    "decay_epoch = 1#decay in lr starts after this epoch\n",
    "size = 256 #crop size\n",
    "input_nc = 3 #number of input channels\n",
    "output_nc = 3 #number of output channels\n",
    "n_cpu = 8 #number of cpu threads to use during batch generation\n",
    "last_epoch = 0 #checkpoint usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "\n",
    "#models\n",
    "netG_A2B = Generator(input_nc, output_nc)\n",
    "netG_B2A = Generator(output_nc, input_nc)\n",
    "netD_A = Discriminator(input_nc)\n",
    "netD_B = Discriminator(output_nc)\n",
    "\n",
    "netG_A2B.to(device)\n",
    "netG_B2A.to(device)\n",
    "netD_A.to(device)\n",
    "netD_B.to(device)\n",
    "\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)\n",
    "\n",
    "#losses\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "#optimizers & lr schedulers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=4 * lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=4 * lr, betas=(0.5, 0.999))\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "\n",
    "#input & target memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if device == 'cuda' else torch.Tensor\n",
    "input_A = Tensor(batchSize, input_nc, size, size)\n",
    "input_B = Tensor(batchSize, output_nc, size, size)\n",
    "target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "#dataset loader\n",
    "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \n",
    "                transforms.CenterCrop(size), \n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "\n",
    "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, unaligned=True), \n",
    "                        batch_size=batchSize, shuffle=True, num_workers=n_cpu)\n",
    "\n",
    "#loss track and #plot\n",
    "logger = Logger(n_epochs, len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloading checkpoint before training\n",
    "\"\"\"\n",
    "netG_A2B.load_state_dict(torch.load('./netG_A2B/checkpoint.pth.tar')['state_dict'])\n",
    "netG_B2A.load_state_dict(torch.load('./netG_B2A/checkpoint.pth.tar')['state_dict'])\n",
    "netD_A.load_state_dict(torch.load('./netD_A/checkpoint.pth.tar')['state_dict'])\n",
    "netD_B.load_state_dict(torch.load('./netD_B/checkpoint.pth.tar')['state_dict'])\n",
    "   \n",
    "optimizer_G.load_state_dict(torch.load('./netG_A2B/checkpoint.pth.tar')['optimizer'])\n",
    "optimizer_D_A.load_state_dict(torch.load('./netD_A/checkpoint.pth.tar')['optimizer'])\n",
    "optimizer_D_B.load_state_dict(torch.load('./netD_B/checkpoint.pth.tar')['optimizer'])\n",
    "epoch = torch.load('./netD_A/checkpoint.pth.tar')['epoch']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "#print(epoch)\n",
    "loss_track_g = []\n",
    "loss_track_gidentity = []\n",
    "loss_track_gcycle = []\n",
    "loss_track_gan = []\n",
    "loss_track_d = []\n",
    "for epoch in range(epoch, n_epochs):\n",
    "    #print(epoch)\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        #set model input\n",
    "        real_A = Variable(input_A.copy_(batch['A']))\n",
    "        real_B = Variable(input_B.copy_(batch['B']))\n",
    "        \n",
    "        ##################################\n",
    "        #generators A2B and B2A\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        #identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*5.0 \n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
    "\n",
    "        #GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake = netD_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        #cycle loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "\n",
    "        #total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ####################################\n",
    "\n",
    "        #discriminator A: between real and fake (generated) A\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        #real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        #fake loss\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        #total loss\n",
    "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "        #print(loss_D_A)\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        #discriminator B\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        #print(loss_D_B)\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        ###################################\n",
    "\n",
    "        #logger report\n",
    "        logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B), 'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
    "                    'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)}, \n",
    "                    images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
    "        loss_track_g.append(loss_G)\n",
    "        loss_track_gidentity.append(loss_identity_A + loss_identity_B)\n",
    "        loss_track_gcycle.append(loss_cycle_ABA + loss_cycle_BAB)\n",
    "        loss_track_gan.append(loss_GAN_A2B + loss_GAN_B2A)\n",
    "        loss_track_d.append(loss_D_A + loss_D_B)\n",
    "\n",
    "    #update lr\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    #save model checkpoints\n",
    "    os.makedirs('./netG_A2B', exist_ok=True)\n",
    "    checkpoint_pathGAB = os.path.join('./netG_A2B', \"checkpoint.pth.tar\")\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': netG_A2B.state_dict(), 'optimizer': optimizer_G.state_dict()}, checkpoint_pathGAB)\n",
    "    os.makedirs('./netG_B2A', exist_ok=True)\n",
    "    checkpoint_pathGBA = os.path.join('./netG_B2A', \"checkpoint.pth.tar\")\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': netG_B2A.state_dict(), 'optimizer': optimizer_G.state_dict()}, checkpoint_pathGBA)\n",
    "    os.makedirs('./netD_A', exist_ok=True)\n",
    "    checkpoint_pathDA = os.path.join('./netD_A', \"checkpoint.pth.tar\")\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': netD_A.state_dict(), 'optimizer': optimizer_D_A.state_dict()}, checkpoint_pathDA)\n",
    "    os.makedirs('./netD_B', exist_ok=True)\n",
    "    checkpoint_pathDB = os.path.join('./netD_B', \"checkpoint.pth.tar\")\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': netD_B.state_dict(), 'optimizer': optimizer_D_B.state_dict()}, checkpoint_pathDB)\n",
    "    with open('losses.txt', 'a') as file:\n",
    "            file.write(\"writing!\\n\")\n",
    "            file.write(\"Finish epoch {}\".format(epoch + 1))\n",
    "            file.write('loss_G' + str(loss_G.item()))\n",
    "            file.write('loss_G_I' + str((loss_identity_A + loss_identity_B).item()))\n",
    "            file.write('loss_G_cyc' + str((loss_cycle_ABA + loss_cycle_BAB).item()))\n",
    "            file.write('loss_GAN' + str((loss_GAN_A2B + loss_GAN_B2A).item()))\n",
    "            file.write('loss_D' + str((loss_D_A + loss_D_B).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_track_g_ar = []\n",
    "loss_track_gidentity_ar = []\n",
    "loss_track_gcycle_ar = []\n",
    "loss_track_gan_ar = []\n",
    "loss_track_d_ar = []\n",
    "\n",
    "for iter in range(1, 510*1):\n",
    "    loss_track_g_ar.append(loss_track_g[iter].item())\n",
    "    loss_track_gidentity_ar.append(loss_track_gidentity[iter].item())\n",
    "    loss_track_gcycle_ar.append(loss_track_gcycle[iter].item())\n",
    "    loss_track_gan_ar.append(loss_track_gan[iter].item())\n",
    "    loss_track_d_ar.append(loss_track_d[iter].item())\n",
    "\n",
    "iter_count = range(1, 510*1)\n",
    "plt.plot(iter_count, loss_track_g_ar, 'r--')\n",
    "plt.plot(iter_count, loss_track_gcycle_ar, 'b-')\n",
    "plt.plot(iter_count, loss_track_gan_ar, 'g-')\n",
    "plt.plot(iter_count, loss_track_d_ar, 'y--')\n",
    "plt.plot(iter_count, loss_track_gidentity_ar, 'k--')\n",
    "\n",
    "plt.legend(['Loss G', 'Loss G Cyclic', 'Loss Adversarial', 'Loss D', 'Loss Identity'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing initialize\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "\n",
    "#if torch.cuda.is_available() and not opt.cuda:\n",
    "#    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "batchSize = 1\n",
    "dataroot = './vangogh2photo'\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "size = 256\n",
    "n_cpu = 8\n",
    "generator_A2B = './netG_A2B/checkpoint.pth.tar'\n",
    "generator_B2A = './netG_B2A/checkpoint.pth.tar'\n",
    "\n",
    "#defining variables\n",
    "#models\n",
    "netG_A2B = Generator(input_nc, output_nc)\n",
    "netG_B2A = Generator(output_nc, input_nc)\n",
    "\n",
    "\n",
    "netG_A2B.to(device)\n",
    "netG_B2A.to(device)\n",
    "\n",
    "#load state dicts - checkpoint models\n",
    "netG_A2B.load_state_dict(torch.load('./netG_A2B/checkpoint.pth.tar')['state_dict'])\n",
    "netG_B2A.load_state_dict(torch.load('./netG_B2A/checkpoint.pth.tar')['state_dict'])\n",
    "\n",
    "#test mode\n",
    "netG_A2B.eval()\n",
    "netG_B2A.eval()\n",
    "\n",
    "#input & target memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if device == 'cuda' else torch.Tensor\n",
    "input_A = Tensor(batchSize, input_nc, size, size)\n",
    "input_B = Tensor(batchSize, output_nc, size, size)\n",
    "\n",
    "#dataset loader\n",
    "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \n",
    "                transforms.CenterCrop(size), \n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "#transforms_ = [ transforms.ToTensor(),\n",
    "#                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, mode='test'), \n",
    "                        batch_size=batchSize, shuffle=False, num_workers=n_cpu)\n",
    "###################################\n",
    "\n",
    "#testing\n",
    "\n",
    "#create output dirs if they don't exist\n",
    "if not os.path.exists('./outputA'):\n",
    "    os.makedirs('./outputA')\n",
    "if not os.path.exists('./outputB'):\n",
    "    os.makedirs('./outputB')\n",
    "\n",
    "test_image = []\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    #set model input\n",
    "    real_A = Variable(input_A.copy_(batch['A']))\n",
    "    real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "    #generate output\n",
    "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "    \n",
    "    #test_image[i] = fake_A\n",
    "    #print(fake_A)\n",
    "    \n",
    "    # Save image files\n",
    "    save_image(fake_A, './outputA/%04d.png' % (i+1))\n",
    "    save_image(fake_B, './outputB/%04d.png' % (i+1))\n",
    "\n",
    "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\n",
    "\n",
    "sys.stdout.write('\\n')\n",
    "###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
