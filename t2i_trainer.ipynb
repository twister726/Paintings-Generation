{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /datasets/home/64/364/rhadden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from decoder import *\n",
    "from encoder import *\n",
    "from textEncoder import *\n",
    "from genZero import *\n",
    "from other_data_loader import *\n",
    "import pickle\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import torchvision.transforms as tf\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate(val_loader, encoder, decoder, embed, stack, maxSeqLen,\n",
    "             vocab, batch_size, use_gpu = True):\n",
    "\n",
    "    \n",
    "    #Evaluation Mode\n",
    "    decoder.eval()\n",
    "    encoder.eval()\n",
    "    embed.eval()\n",
    "    stack.eval()\n",
    "\n",
    "    # critereon\n",
    "    discCrit = nn.BCEWithLogitsLoss()\n",
    "    textCrit = nn.CrossEntropyLoss()\n",
    "    distCrit = nn.SmoothL1Loss()\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        count    = 0\n",
    "        loss_avg = 0\n",
    "\n",
    "                \n",
    "        for i, (inputs, labels, lengths) in enumerate(val_loader):\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Move to device, if available\n",
    "            if use_gpu:\n",
    "                inputs = inputs.to(device)# Move your inputs onto the gpu\n",
    "                labels = labels.to(device) # Move your labels onto the gpu\n",
    "                        \n",
    "\n",
    "            #STEM\n",
    "            embed.resetHidden(labels.shape[0])\n",
    "            pred_out, w, s = embed(labels, lengths)\n",
    "            \n",
    "            #GLAM\n",
    "            generated_imgs, h0s, discr_gen, discr_real = stackZero(s, inputs)\n",
    "            \n",
    "            \n",
    "            # STREAM\n",
    "            enc_out = encoder(generated_imgs)\n",
    "\n",
    "            decoder.resetHidden(inputs.shape[0])\n",
    "            outputs = decoder(labels, enc_out, lengths) #calls forward\n",
    "            \n",
    "            \n",
    "            loss = (\n",
    "                    distCrit(generated_imgs, inputs)\n",
    "                    + textCrit(outputs, labels.cuda())\n",
    "                    + discCrit(discr_real, torch.ones(discr_real.shape).cuda())\n",
    "            )\n",
    "            \n",
    "            loss_avg += loss.item()\n",
    "            count+=1\n",
    "            \n",
    "            \n",
    "            del caps\n",
    "            del outputs            \n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "        loss_avg  = loss_avg/count\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainStack(encoder, decoder, embed, stackZero, epochs, train_loader,val_loader, test_loader,\n",
    "                        name, batch_size, maxSeqLen, vocab,save_generated_imgs= False):\n",
    "    \n",
    "    #Create non-existing logfiles\n",
    "    logname = './logs/' + name + '.log'\n",
    "    i = 0\n",
    "    if os.path.exists(logname) == True:\n",
    "        \n",
    "        logname = './logs/' + name + str(i) + '.log'\n",
    "        while os.path.exists(logname):\n",
    "            i+=1\n",
    "            logname = './logs/' + name + str(i) + '.log'\n",
    "\n",
    "    print('Loading results to logfile: ' + logname)\n",
    "    with open(logname, \"w\") as file:\n",
    "        file.write(\"Log file DATA: Validation Loss and Accuracy\\n\") \n",
    "    \n",
    "    logname_summary = './logs/' + name + '_summary' + str(i) + '.log'    \n",
    "    print('Loading Summary to : ' + logname_summary) \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        os.mkdir('./generated_imgs')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    generated_imgs_filename = './generated_imgs/generated_imgs' + name + '_summary' + str(i) + '.log'\n",
    "    \n",
    "    parameters = list(stackZero.parameters())\n",
    "    optimizer = optim.Adam(parameters, lr=5e-5)\n",
    "    \n",
    "    \n",
    "    discCrit = nn.BCEWithLogitsLoss()\n",
    "    textCrit = nn.CrossEntropyLoss()\n",
    "    distCrit = nn.SmoothL1Loss()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "\n",
    "        encoder.to(device)\n",
    "        decoder.to(device)\n",
    "        embed.to(device)\n",
    "        stackZero.to(device)\n",
    "    temperature=1\n",
    "    \n",
    "    val_loss_set = []\n",
    "\n",
    "    training_loss = []\n",
    "    \n",
    "    # Early Stop criteria\n",
    "    minLoss = 1e6\n",
    "    minLossIdx = 0\n",
    "    earliestStopEpoch = 7\n",
    "    earlyStopDelta = 3\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "\n",
    "        for iter, (inputs, labels, lengths) in tqdm(enumerate(train_loader)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            stackZero.train()\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "            embed.train()\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.to(device)# Move your inputs onto the gpu\n",
    "                labels = labels.to(device) # Move your labels onto the gpu\n",
    "            \n",
    "            #STEM\n",
    "            embed.resetHidden(labels.shape[0])\n",
    "            pred_out, w, s = embed(labels, lengths)\n",
    "            \n",
    "            #GLAM\n",
    "            generated_imgs, h0s, discr_gen, discr_real = stackZero(s, inputs)\n",
    "            \n",
    "            \n",
    "            # STREAM\n",
    "            enc_out = encoder(generated_imgs)\n",
    "\n",
    "            decoder.resetHidden(inputs.shape[0])\n",
    "            outputs = decoder(labels, enc_out, lengths) #calls forward\n",
    "            \n",
    "            #For first epoch will train the discriminator/generator everyother iteration\n",
    "            if epoch ==0:\n",
    "                if iter % 2 == 0:\n",
    "                    # Train discriminator\n",
    "                    loss = (\n",
    "                        distCrit(generated_imgs, inputs)\n",
    "                        + textCrit(outputs, labels.cuda())\n",
    "                        - discCrit(discr_gen, torch.zeros(discr_gen.shape).cuda())\n",
    "                    )\n",
    "                else:\n",
    "                    # Train generator\n",
    "                    loss = (\n",
    "                        discCrit(discr_gen, torch.zeros(discr_gen.shape).cuda()) \n",
    "                        + discCrit(discr_real, torch.ones(discr_real.shape).cuda())\n",
    "                    )\n",
    "                    \n",
    "            # After first epoch will train discriminator every 5 epochs\n",
    "            elif epoch % 5:\n",
    "                # Train discriminator\n",
    "                loss = (\n",
    "                        discCrit(discr_gen, torch.zeros(discr_gen.shape).cuda()) \n",
    "                        + discCrit(discr_real, torch.ones(discr_real.shape).cuda())\n",
    "                )\n",
    "            else:\n",
    "                # Train generator\n",
    "                loss = (\n",
    "                    distCrit(generated_imgs, inputs)\n",
    "                    + textCrit(outputs, labels)\n",
    "                    - discCrit(discr_gen, torch.zeros(discr_gen.shape).cuda())\n",
    "                )\n",
    "            \n",
    "#             del labels\n",
    "#             del outputs\n",
    "\n",
    "            loss.backward()\n",
    "#             loss = loss#.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 200 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "                \n",
    "        print(\"epoch{}, iter{}, loss: {}, epoch duration: {}\".format(epoch, iter, loss, time.time() - ts))\n",
    "        test_pred = decoder.generate_caption(enc_out, maxSeqLen, temperature).cpu()\n",
    "        \n",
    "        k = 0\n",
    "        for b in range(inputs.shape[0]):\n",
    "            gen_caption = (\" \").join(\n",
    "                [vocab.idx2word[x.item()] for x in test_pred[b] if vocab.idx2word[x.item()] is not '<pad>'])\n",
    "            raw_caption = (\" \").join(\n",
    "                [vocab.idx2word[x.item()] for x in labels[b] if vocab.idx2word[x.item()] is not '<pad>'])\n",
    "            gen_img = tf.ToPILImage()(generated_imgs[b,:,:,:].cpu())\n",
    "            raw_img = tf.ToPILImage()(inputs[b,:,:,:].cpu())\n",
    "                    \n",
    "            plt.figure(figsize=(14,8))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(raw_img)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(gen_img)      \n",
    "            plt.show()\n",
    "            print(\"Base Caption: \" + raw_caption)\n",
    "            print(\"Generated Caption: \" + gen_caption)\n",
    "            \n",
    "            if save_generated_imgs:\n",
    "                file = \"./generated_imgs/\" + \"train_epoch\" + str(epoch) + \"im_\"+ str(k) \n",
    "                img.save(file + \".png\", \"PNG\")\n",
    "                k+=1\n",
    "                with open(generated_imgs_filename, \"a\") as file:\n",
    "                    file.write(\"writing! \" + \"train_epoch\" + str(epoch) + \"im_\"+ str(k) + \"\\n\")            \n",
    "                    file.write(\"Caption: \" + caption +\"\\n \\n\")\n",
    "        del labels\n",
    "        del outputs\n",
    "        # calculate val loss each epoch\n",
    "        val_loss = validate(val_loader, encoder, decoder, embed, stackZero, maxSeqLen,\n",
    "                             vocab, batch_size, use_gpu)\n",
    "        val_loss_set.append(val_loss)\n",
    "\n",
    "        print(\"epoch{}, iter{}, val loss: {}, epoch duration: {}\".format(epoch, iter, val_loss, time.time() - ts))\n",
    "        \n",
    "      \n",
    "        training_loss.append(loss)\n",
    "        \n",
    "        torch.save(stackZero, 'weights/stack0_{}_epoch{}'.format(name, epoch))\n",
    "\n",
    "        \n",
    "        with open(logname, \"a\") as file:\n",
    "            file.write(\"writing!\\n\")\n",
    "            file.write(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "            file.write(\"\\n training Loss:   \" + str(loss.item()))\n",
    "            file.write(\"\\n Validation Loss: \" + str(val_loss_set[-1]))\n",
    "                                          \n",
    "                                                                                                \n",
    "                                                                                                \n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < minLoss:\n",
    "            # Store new best\n",
    "            torch.save(stackZero, 'weights/stack0_{}_best'.format(name))\n",
    "            minLoss = val_loss#.item()\n",
    "            minLossIdx = epoch\n",
    "            \n",
    "        #If passed min threshold, and no new min has been reached for delta epochs\n",
    "        elif epoch > earliestStopEpoch and (epoch - minLossIdx) > earlyStopDelta:\n",
    "            print(\"Stopping early at {}\".format(minLossIdx))\n",
    "            break\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        with open(logname_summary, \"w\") as file:\n",
    "            file.write(\"Summary!\\n\")\n",
    "            #file.write(\"Stopped early at {}\".format(minLossIdx))\n",
    "            file.write(\"\\n training Loss:   \" + str(training_loss))        \n",
    "            file.write(\"\\n Validation Loss : \" + str(val_loss_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 7323 train ids\n",
      "found 866 test ids\n",
      "# ids: 58590\n",
      "# ids: 14640\n",
      "# ids: 8660\n",
      "Loading results to logfile: ./logs/stackZero.log\n",
      "Loading Summary to : ./logs/stackZero_summary0.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: -0.7631231546401978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:01,  1.03s/it]\u001b[A\n",
      "3it [00:01,  1.27it/s]\u001b[A\n",
      "5it [00:02,  1.73it/s]\u001b[A\n",
      "6it [00:02,  2.27it/s]\u001b[A\n",
      "7it [00:02,  2.93it/s]\u001b[A\n",
      "8it [00:02,  3.70it/s]\u001b[A\n",
      "9it [00:02,  4.34it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    with open('trainvalIds.csv', 'r') as f:\n",
    "        trainIds = []\n",
    "        for line in f:\n",
    "            if len(line) > 1:\n",
    "                trainIds.append(line.strip(\"\\n\"))\n",
    "\n",
    "        \n",
    "    with open('testIds.csv', 'r') as f:\n",
    "        testIds = []\n",
    "        for line in f:\n",
    "            if len(line) > 1:\n",
    "                testIds.append(line.strip(\"\\n\"))\n",
    "    \n",
    "    print(\"found {} train ids\".format(len(trainIds)))\n",
    "    print(\"found {} test ids\".format(len(testIds)))\n",
    "    \n",
    "    # Will shuffle the trainIds incase of ordering in csv\n",
    "    random.shuffle(trainIds)\n",
    "    splitIdx = int(len(trainIds)/5)\n",
    "    \n",
    "    # Selecting 1/5 of training set as validation\n",
    "    valIds = trainIds[:splitIdx]\n",
    "    trainIds = trainIds[splitIdx:]\n",
    "    #print(trainIds)\n",
    "    \n",
    "    \n",
    "    trainValRoot = \"./data/realImages/\"\n",
    "    testRoot = \"./data/realImages/\"\n",
    "    \n",
    "    trainValCaps = \"./data/captions/trainvalCaps.csv\"\n",
    "    testCaps = \"./data/captions/testCaps.csv\"\n",
    "    \n",
    "    \n",
    "    with open('./data/vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    img_side_length = 64\n",
    "    transform = tf.Compose([\n",
    "        tf.Resize(img_side_length),\n",
    "        #tf.RandomCrop(img_side_length),\n",
    "        tf.CenterCrop(img_side_length),\n",
    "        tf.ToTensor(),\n",
    "    ])\n",
    "    batch_size = 20\n",
    "    shuffle = True\n",
    "    num_workers = 20\n",
    "    \n",
    "    \n",
    "    trainDl = get_loader(trainValRoot, trainValCaps, trainIds, vocab, \n",
    "                         transform=transform, batch_size=batch_size, \n",
    "                         shuffle=shuffle, num_workers=num_workers)\n",
    "    valDl = get_loader(trainValRoot, trainValCaps, valIds, vocab, \n",
    "                         transform=transform, batch_size=batch_size, \n",
    "                         shuffle=shuffle, num_workers=num_workers)\n",
    "    testDl = get_loader(testRoot, testCaps, testIds, vocab, \n",
    "                        transform=transform, batch_size=batch_size, \n",
    "                        shuffle=shuffle, num_workers=num_workers)\n",
    "    \n",
    "    encoded_feature_dim = 800\n",
    "    maxSeqLen = 49\n",
    "    hidden_dim = 1500\n",
    "    depth = 1\n",
    "    \n",
    "    embed = torch.load('./weights/bs{}_embed_best'.format(batch_size))\n",
    "    \n",
    "    encoder = torch.load('./weights/lstm{}encoder_best'.format(img_side_length))\n",
    "    decoder = torch.load('./weights/lstm{}decoder_best'.format(img_side_length))\n",
    "    # Turn off all gradients in encoder\n",
    "    for param in embed.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    for param in encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in decoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    \n",
    "#     criterion = nn.NLLLoss()\n",
    "    stackZero = BaseGenerator(batch_size, embed.hidden_dim)\n",
    "    \n",
    "    epochs = 100\n",
    "    trainStack(encoder, decoder, embed, stackZero, epochs,\n",
    "                        trainDl, valDl, testDl, \"stackZero\",\n",
    "                        batch_size, maxSeqLen, vocab,save_generated_imgs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "vocab.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "#print(os.getcwd())\n",
    "embed = torch.load('./weights/base_embed_best')\n",
    "embed.batch_size\n",
    "optimizer = optim.Adam(list(embed.parameters()), lr=5e-5)\n",
    "\n",
    "help(optimizer.step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
